
#' @param path where QDNAseq raw and corrected read files are REQ
#' @param raw.file.grep for the filename of the raw reads file, default is 'raw.*read'
#' @param corrected.file.grep for the filename of the corrected reads file, default is 'corr|fitted'
#' @return BarrettsRiskRx object with several fields: $predictions provides a table for the probability, risk, and relative risk for each sample; and $rx provides a table for the recommendations generated by the model and the demographics file (if available).
#'
#' @author skillcoyne
#' @export
predictRisk<-function(path='.', raw.file.grep='raw.*read', corrected.file.grep='corr|fitted', verbose=T) {

  rawFile = grep(raw.file.grep, list.files(path, pattern='txt', full.names=T), value=T, ignore.case=T)
  corrFile = grep(corrected.file.grep, list.files(path, pattern='txt', full.names=T), value=T,ignore.case=T)

  if (length(rawFile) <= 0 | length(corrFile) <= 0)
    stop(paste("Raw reads file or corrected reads file not found in directory:", path))

  if (length(rawFile) > 1 | length(corrFile) > 1)
    stop(paste("Too many raw or corrected read files to select from:", path))

  if (verbose)
    message(paste("Raw reads file: ", rawFile, "\n", "Corrected reads file: ", corrFile, "\n", sep=''))

  beModel = .loadModel()

  raw.data = as_tibble(data.table::fread(rawFile,stringsAsFactors=F, showProgress=verbose))
  fit.data = as_tibble(data.table::fread(corrFile,stringsAsFactors=F,showProgress=verbose))

  if (length(which(dim(raw.data) == dim(fit.data))) != 2)
    stop("Raw and corrected read files do not have the same number of rows or columns.")

  descCols = grep('loc|chr|start|end',colnames(raw.data))
  if (length(descCols) != 4)
    stop("File needs the following genome information columns: location chrom start end.\nAll additional column should be samples.")

  sampleCols = grep('loc|chr|start|end',colnames(raw.data), invert=T)
  if (length(sampleCols) < 1)
    stop("No sample columns found after genome information columns.")

  if(length(which(sapply(raw.data[,sampleCols], is.integer))) < length(sampleCols))
    stop(paste("Sample columns in raw read count file contain non-integer data."))

  if(length(which(sapply(fit.data[,sampleCols], is.double))) < length(sampleCols))
    stop(paste("Sample columns in fitted read count file contain integer data, fractional values expected."))

  if (verbose) message(paste(length(sampleCols), "sample(s) loaded from",rawFile))

  segmented = segmentRawData(raw.data,fit.data,verbose=verbose)

  segtiles = tileSegments(segmented$seg.vals, size=5e6,verbose=verbose)
  for (i in 1:ncol(segtiles))
    segtiles[,i] = unit.var(segtiles[,i], beModel$z.mean[i], beModel$z.sd[i])

  armtiles = tileSegments(segmented$seg.vals, size='arms',verbose=verbose)
  for (i in 1:ncol(armtiles))
    armtiles[,i] = unit.var(armtiles[,i], beModel$z.arms.mean[i], beModel$z.arms.sd[i])

  cx.score = unit.var(scoreCX(segtiles,1), beModel$mn.cx, beModel$sd.cx)

  mergedDf = subtractArms(segtiles, armtiles)
  mergedDf = cbind(mergedDf, 'cx'=cx.score)

  sparsed_test_data = Matrix(data=0, nrow=nrow(mergedDf),  ncol=ncol(mergedDf),
                             dimnames=list(rownames(mergedDf),colnames(mergedDf)), sparse=T)
  for(i in colnames(mergedDf)) sparsed_test_data[,i] = mergedDf[,i]

  probs = predict(beModel$model, newx=sparsed_test_data, s=beModel$lambda, type='response')
  RR = predict(beModel$model, newx=sparsed_test_data, s=beModel$lambda, type='link')

  preds = tibble('Sample'=rownames(probs), 'Probability'=probs[,1],
                 'Relative Risk'=RR[,1], 'Risk'=sapply(probs[,1], .risk))

  psp = list('predictions'=preds, 'segmented'=segmented, 'BEModel'=beModel)
  class(psp) <- c('BarrettsRiskRx', class(psp))
  return(psp)
}


#' @param BarrettsRiskRx object
#' @return
#'
#' @author skillcoyne
#' @export
plotSegmentData<-function(brr) {
  if (class(BarrettsRiskRx)[1] != 'BarrettsRiskRx')
    stop("BarrettsRiskRx object missing")

  do.call(gridExtra::grid.arrange, brr$segmented$seg.plots)
}


#' Use with caution. These are based on estimates of what we think the risk might really be #' and adjusting the resulting risk based on those estimates.
#' @param BarrettsRiskRx object
#' @param offset c(min,mean,max)
#' @return BarrettsRiskRx object with adjusted predictions and recommentations.
#'
#' @author skillcoyne
#' @export
adjustRisk <- function(BarrettsRiskRx, offset=c('min','mean','max')) {
  if (class(BarrettsRiskRx)[1] != 'BarrettsRiskRx')
    stop("BarrettsRiskRx object missing")

  if (length(grep('BEModel',names(BarrettsRiskRx))) <= 0)
    stop("Original BarrettsRiskRx object required. Adjusted object cannot be re-adjusted.")

  offset = switch(offset,
         min=BarrettsRiskRx$BEModel$minOffset[,1],
         max=BarrettsRiskRx$BEModel$maxOffset[,1],
         mean=BarrettsRiskRx$BEModel$meanOffset[,1])

  RR = BarrettsRiskRx$predictions$`Relative Risk`

  adjustedRiskRx = BarrettsRiskRx$predictions

  adjustedRiskRx$Probability = 1/(1+exp(-RR+abs(offset)))
  adjustedRiskRx$`Relative Risk` = RR+offset
  adjustedRiskRx$Risk = sapply(adjustedRiskRx$Probability, .risk)

  psp = list('predictions'=adjustedRiskRx)
  class(psp) <- c('BarrettsRiskRx', class(psp))
  return(psp)
}

#' @param BarrettsRiskRx object REQ
#' @return
#'
#' @author skillcoyne
#' @export
predictions<-function(brr) {
  if (class(BarrettsRiskRx)[1] != 'BarrettsRiskRx')
    stop("BarrettsRiskRx object missing")
  brr$predictions
}

#' Times per sample are determined by the order of the sample as given by the demoFile, or by the order of the samples in the dataset.
#' @param BarrettsRiskRx object REQ
#' @param demoFile for the tab-delimited file that contains a per-sample entry for p53 IHC, Barrett's segment length, patient gender OPTIONAL
#' @return A table that includes recommendations per timepoint.
#'
#' @author skillcoyne
#' @export
rx<-function(brr, demoFile=NULL) {
  if (class(brr)[1] != 'BarrettsRiskRx')
    stop("BarrettsRiskRx object required")

  pR = brr$predictions

  if (!is.null(demoFile))
    pR = .loadDemoData(demoFile, pR$Sample, pR)

  pR$Risk = factor(pR$Risk, levels=c('Low','Moderate','High'), ordered=T)
  pR$Sample = as.character(pR$Sample)
  p53Col = grep('p53', colnames(pR), value=T, ignore.case=T)
  pathCol = grep('path', colnames(pR), value=T, ignore.case=T)

  rules = as.data.frame(matrix(ncol=3, nrow=nrow(pR), dimnames=list(c(), c('Time 1','Time 2','rule'))))
  # Consecutive
  for (i in 1:nrow(pR)) {
    risks = table(pR$Risk[i:(i+1)])
    p53 = NULL
    if (length(p53Col) > 0) {
      pR[[p53Col]] = factor(pR[[p53Col]], levels=c(0,1))
      p53 = table(pR[[p53Col]][i:(i+1)])
    }

    rule = 'None'
    if ( risks['High'] == 2 || (length(pathCol) > 0 && length(which(grepl('HGD|IMC', pR[[pathCol]][i:(i+1)]))) > 0) ) {
      rule = 1
    } else if ( risks['High'] == 1 || (!is.null(p53) && p53['1'] > 0) ) {
      rule = 2
    } else if ( risks['Moderate'] > 0 || (risks['Low'] ==1 && nrow(pR) == 1)) {
      rule = 3
    } else if ( risks['Low'] == 2 ) {
      rule = 4
    }
    rules[i,] = cbind( pR$Sample[i], pR$Sample[(i+1)], as.integer(rule) )
  }
  rules$rule = as.integer(rules$rule)
  rules$Rx = sapply(rules$rule, .rule.rx)

  return(rules)
}

.rule.rx<-function(n) {
  rr = c('Immediate RFA', 'Recheck 6-12 months',
         'Recheck 12-24 months','Regular surveillance 3-5 years')
  return(rr[n])
}

.loadModel<-function() {
  # TODO load into a single data file only the pieces we need in order to generate predictions
  load('inst/model_data.Rdata',verbose=F)
  load('inst/all.pt.alpha.Rdata',verbose=F)

  fitV = models$`0.9`
  lambda = performance.at.1se$`0.9`$lambda

  total = cbind.data.frame('NP'=43,'P'=45)

  cases = total['P']

  mn = round((cases/(0.01*100))*100)
  m = round((cases/(0.0225*100))*100)
  mx = round((cases/(0.035*100))*100)

  offsetMin = log(cases/mn)
  offsetMean = log(cases/m)
  offsetMax = log(cases/mx)

  rm(raw.segs,raw.arms,labels,plots,dysplasia.df,performance.at.1se,models)

  beModel = list(
                'model'=fitV, 'lambda'=lambda,
                'mn.cx'=mn.cx, 'sd.cx'=sd.cx, 'z.mean'=z.mean,'z.sd'=z.sd,
                'z.arms.mean'=z.arms.mean, 'z.arms.sd'=z.arms.sd,
                'minOffset'=offsetMin, 'maxOffset'=offsetMax, 'meanOffset'=offsetMean)
  class(beModel) = c('BEModel', class(beModel))

  return(beModel)
}

## TODO this needs to be  set up in the model data that gets loaded, not hardcoded here
.risk<-function(p) {
  if (!is.numeric(p) | (p > 1 | p < 0) ) stop("Numeric probability between 0-1 required")
  risk = ''
  if (p < 0.3 ) {
    risk = 'Low'
  } else if (p >= 0.3 & p < 0.7) {
    risk = 'Moderate'
  } else if ( p >= 0.7 ) {
    risk = 'High'
  }
  return(risk)
}


.loadDemoData<-function(file, samplenames, predDf) {

  demo = as.data.frame(data.table::fread(file))

  if (nrow(demo) > length(samplenames)) {
    warning(paste("Not all samples in",file,"are represented in the data files."))
    demo = subset(demo, Sample %in% samplenames)
  }

  if (nrow(demo) < length(samplenames)) {
    warning(paste("Fewer samples in",file,"than in the data files. Ignoring demo data."))
    return(NULL)
  }

  path = grep('path',colnames(demo),ignore.case=T,value=T)
  p53 = grep('p53',colnames(demo),ignore.case=T,value=T)

  if( length(path) <= 0 | length(p53) <= 0 ) {
    warning(paste("p53 IHC or pathology not available, recommendations will be limited to available information and risk prediction."))
  }

  beLen = grep('length',colnames(demo),ignore.case=T,value=T)
  gender = grep('gender|sex',colnames(demo),ignore.case=T,value=T)

  preds = base::merge(predDf, demo[,c('Sample',path,p53,beLen,gender)],by='Sample')

  #intersect(demo$Sample, preds$Sample)

  return(preds)
}
